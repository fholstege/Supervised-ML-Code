xlength <- 150  # number of iteration. we actually don't know
y_bottom <- -2.5
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS))
calcModelMM <- function(mX,mY,e, nBeta){
# print("Number of variables:")
# print(nBeta)
##################
firstRSS <- 0    # initial RSS
i <- 0          # x axis counter
x_axis <- i     # x axis
y_axis <- 0  # y axis
xlength <- 150  # number of iteration. we actually don't know
y_bottom <- -2.5
# Initial plot
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS))
################
if(nBeta > ncol(mX) + 1){
stop("You want to use more variables than there are in the dataset of independent variables")
}
# set the previous beta to initial, random beta's
prevBeta <- getB0(mX)
# calculate X'X
mXtX <- t(mX) %*% mX
# get largest eigenvalue for the square of independent variables
Lambda <- calcLargestEigen(mXtX)
# set initial stepscore to 0, k to 1.
StepScore <- 0
k <- 1
#####################
newRSS <- firstRSS
# run while, either if k is equal to 1, or the improvement between k-1th and kth set of beta's is smaller than the parameter e
while (k == 1 | StepScore > e ){
# step to next k
k <- k + 1
# calculate beta's for this k
BetaK <- calcBetaK(prevBeta, Lambda, mX,mY)
# sort the beta's based on absolute value, remove the smallest ones to keep m
absBetaKOrdered <- order(abs(BetaK[,1]), decreasing = T)
BetaK[!BetaK %in% BetaK[absBetaKOrdered,][1:nBeta]] <- 0
# new stepscore, % difference in RSS between new Beta's and previous beta's
StepScore <- calcStepScore(mX,mY,prevBeta,BetaK)
##########
# print(i)
# print(StepScore)
# print(log(StepScore))
# Updating variables for the plot
newRSS <- newRSS - StepScore
i <- i + 1
x_axis <- c(x_axis, i)
y_axis <- c(y_axis, newRSS)
# Add the new bit
# plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(-200, log(firstRSS)))
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, newRSS))
###########
# assign current beta's to prevBeta variable for next iteration
prevBeta <- BetaK
}
# calculate several attributes of the linear model, put in dataframes or doubles
BetaFinal <- as.matrix((BetaK))
RSSBetaK <- calcRSS(mX,mY, BetaK)
mYest <- calcYest(mX, BetaFinal)
Rsquared <- calcRsquared(mY, mYest)
adjRsquared <- calcRsquared(mY,mYest, adjusted = T, p = nBeta-2)
Resi <- data.frame(residuals = mY - mYest)
# add these attributes together as a list to make it easily accessible
results <- list(Beta = BetaFinal, RSS = RSSBetaK, Yest = mYest, Rsquared = Rsquared, adjRsquared = adjRsquared, Residuals = Resi)
return(results)
}
##################################
# findModelMM
# finds th
modelMM <- calcModelMM(mXairIntercept, mYair, e, nBeta)
calcModelMM <- function(mX,mY,e, nBeta){
# print("Number of variables:")
# print(nBeta)
##################
firstRSS <- 0    # initial RSS
i <- 0          # x axis counter
x_axis <- i     # x axis
y_axis <- 0  # y axis
xlength <- 150  # number of iteration. we actually don't know
y_bottom <- -2.5
# Initial plot
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS))
################
if(nBeta > ncol(mX) + 1){
stop("You want to use more variables than there are in the dataset of independent variables")
}
# set the previous beta to initial, random beta's
prevBeta <- getB0(mX)
# calculate X'X
mXtX <- t(mX) %*% mX
# get largest eigenvalue for the square of independent variables
Lambda <- calcLargestEigen(mXtX)
# set initial stepscore to 0, k to 1.
StepScore <- 0
k <- 1
#####################
newRSS <- firstRSS
# run while, either if k is equal to 1, or the improvement between k-1th and kth set of beta's is smaller than the parameter e
while (k == 1 | StepScore > e ){
# step to next k
k <- k + 1
# calculate beta's for this k
BetaK <- calcBetaK(prevBeta, Lambda, mX,mY)
# sort the beta's based on absolute value, remove the smallest ones to keep m
absBetaKOrdered <- order(abs(BetaK[,1]), decreasing = T)
BetaK[!BetaK %in% BetaK[absBetaKOrdered,][1:nBeta]] <- 0
# new stepscore, % difference in RSS between new Beta's and previous beta's
StepScore <- calcStepScore(mX,mY,prevBeta,BetaK)
##########
# print(i)
# print(StepScore)
# print(log(StepScore))
# Updating variables for the plot
newRSS <- newRSS - StepScore
i <- i + 1
x_axis <- c(x_axis, i)
y_axis <- c(y_axis, newRSS)
# Add the new bit
# plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(-200, log(firstRSS)))
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS))
###########
# assign current beta's to prevBeta variable for next iteration
prevBeta <- BetaK
}
# calculate several attributes of the linear model, put in dataframes or doubles
BetaFinal <- as.matrix((BetaK))
RSSBetaK <- calcRSS(mX,mY, BetaK)
mYest <- calcYest(mX, BetaFinal)
Rsquared <- calcRsquared(mY, mYest)
adjRsquared <- calcRsquared(mY,mYest, adjusted = T, p = nBeta-2)
Resi <- data.frame(residuals = mY - mYest)
# add these attributes together as a list to make it easily accessible
results <- list(Beta = BetaFinal, RSS = RSSBetaK, Yest = mYest, Rsquared = Rsquared, adjRsquared = adjRsquared, Residuals = Resi)
return(results)
}
#####
modelMM <- calcModelMM(mXairIntercept, mYair, e, nBeta)
log(-20)
log(80)
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
firstRSS <- 3    # initial RSS
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
plot(x_axis, y_axis, xlim = c(0,xlength), log = "y")
firstRSS <- 3    # initial RSS
i <- 0          # x axis counter
x_axis <- i     # x axis
y_axis <- 0  # y axis
xlength <- 150  # number of iteration. we actually don't know
y_bottom <- 0
# Initial plot
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
################
y_bottom <- 0
y_bottom <- 0
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
ylim
y_bottom
firstRAA
firstRSS
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
y_bottom <- 0.0001
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
y_axis <- 0.0001  # y axis
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
calcModelMM <- function(mX,mY,e, nBeta){
# print("Number of variables:")
# print(nBeta)
##################
firstRSS <- 3    # initial RSS
i <- 0          # x axis counter
x_axis <- i     # x axis
y_axis <- 0.0001  # y axis
xlength <- 150  # number of iteration. we actually don't know
y_bottom <- 0.0001
# Initial plot
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
################
if(nBeta > ncol(mX) + 1){
stop("You want to use more variables than there are in the dataset of independent variables")
}
# set the previous beta to initial, random beta's
prevBeta <- getB0(mX)
# calculate X'X
mXtX <- t(mX) %*% mX
# get largest eigenvalue for the square of independent variables
Lambda <- calcLargestEigen(mXtX)
# set initial stepscore to 0, k to 1.
StepScore <- 0
k <- 1
#####################
newRSS <- firstRSS
# run while, either if k is equal to 1, or the improvement between k-1th and kth set of beta's is smaller than the parameter e
while (k == 1 | StepScore > e ){
# step to next k
k <- k + 1
# calculate beta's for this k
BetaK <- calcBetaK(prevBeta, Lambda, mX,mY)
# sort the beta's based on absolute value, remove the smallest ones to keep m
absBetaKOrdered <- order(abs(BetaK[,1]), decreasing = T)
BetaK[!BetaK %in% BetaK[absBetaKOrdered,][1:nBeta]] <- 0
# new stepscore, % difference in RSS between new Beta's and previous beta's
StepScore <- calcStepScore(mX,mY,prevBeta,BetaK)
##########
# print(i)
# print(StepScore)
# print(log(StepScore))
# Updating variables for the plot
newRSS <- newRSS - StepScore
i <- i + 1
x_axis <- c(x_axis, i)
y_axis <- c(y_axis, newRSS)
# Add the new bit
# plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(-200, log(firstRSS)))
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), log = "y")
###########
# assign current beta's to prevBeta variable for next iteration
prevBeta <- BetaK
}
# calculate several attributes of the linear model, put in dataframes or doubles
BetaFinal <- as.matrix((BetaK))
RSSBetaK <- calcRSS(mX,mY, BetaK)
mYest <- calcYest(mX, BetaFinal)
Rsquared <- calcRsquared(mY, mYest)
adjRsquared <- calcRsquared(mY,mYest, adjusted = T, p = nBeta-2)
Resi <- data.frame(residuals = mY - mYest)
# add these attributes together as a list to make it easily accessible
results <- list(Beta = BetaFinal, RSS = RSSBetaK, Yest = mYest, Rsquared = Rsquared, adjRsquared = adjRsquared, Residuals = Resi)
return(results)
}
##################################
# fin
modelMM <- calcModelMM(mXairIntercept, mYair, e, nBeta)
calcModelMM <- function(mX,mY,e, nBeta){
# print("Number of variables:")
# print(nBeta)
##################
firstRSS <- 3    # initial RSS
i <- 0          # x axis counter
x_axis <- i     # x axis
y_axis <- 1  # y axis
xlength <- 80  # number of iteration. we actually don't know
y_bottom <- 0.0001
# Initial plot
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS))
################
if(nBeta > ncol(mX) + 1){
stop("You want to use more variables than there are in the dataset of independent variables")
}
# set the previous beta to initial, random beta's
prevBeta <- getB0(mX)
# calculate X'X
mXtX <- t(mX) %*% mX
# get largest eigenvalue for the square of independent variables
Lambda <- calcLargestEigen(mXtX)
# set initial stepscore to 0, k to 1.
StepScore <- 0
k <- 1
#####################
newRSS <- firstRSS
# run while, either if k is equal to 1, or the improvement between k-1th and kth set of beta's is smaller than the parameter e
while (k == 1 | StepScore > e ){
# step to next k
k <- k + 1
# calculate beta's for this k
BetaK <- calcBetaK(prevBeta, Lambda, mX,mY)
# sort the beta's based on absolute value, remove the smallest ones to keep m
absBetaKOrdered <- order(abs(BetaK[,1]), decreasing = T)
BetaK[!BetaK %in% BetaK[absBetaKOrdered,][1:nBeta]] <- 0
# new stepscore, % difference in RSS between new Beta's and previous beta's
StepScore <- calcStepScore(mX,mY,prevBeta,BetaK)
##########
# print(i)
# print(StepScore)
# print(log(StepScore))
# Updating variables for the plot
newRSS <- newRSS - StepScore
i <- i + 1
x_axis <- c(x_axis, i)
y_axis <- c(y_axis, newRSS)
# Add the new bit
# plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(-200, log(firstRSS)))
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS))
###########
# assign current beta's to prevBeta variable for next iteration
prevBeta <- BetaK
}
# calculate several attributes of the linear model, put in dataframes or doubles
BetaFinal <- as.matrix((BetaK))
RSSBetaK <- calcRSS(mX,mY, BetaK)
mYest <- calcYest(mX, BetaFinal)
Rsquared <- calcRsquared(mY, mYest)
adjRsquared <- calcRsquared(mY,mYest, adjusted = T, p = nBeta-2)
Resi <- data.frame(residuals = mY - mYest)
# add these attributes together as a list to make it easily accessible
results <- list(Beta = BetaFinal, RSS = RSSBetaK, Yest = mYest, Rsquared = Rsquared, adjRsquared = adjRsquared, Residuals = Resi)
return(results)
}
##################################
# findMo
modelMM <- calcModelMM(mXairIntercept, mYair, e, nBeta)
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 21)
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 19)
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 16)
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 16)
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 20)
calcModelMM <- function(mX,mY,e, nBeta){
# print("Number of variables:")
# print(nBeta)
##################
firstRSS <- 3    # initial RSS
i <- 0          # x axis counter
x_axis <- i     # x axis
y_axis <- 1  # y axis
xlength <- 80  # number of iteration. we actually don't know
y_bottom <- 0.0001
# Initial plot
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 20)
################
if(nBeta > ncol(mX) + 1){
stop("You want to use more variables than there are in the dataset of independent variables")
}
# set the previous beta to initial, random beta's
prevBeta <- getB0(mX)
# calculate X'X
mXtX <- t(mX) %*% mX
# get largest eigenvalue for the square of independent variables
Lambda <- calcLargestEigen(mXtX)
# set initial stepscore to 0, k to 1.
StepScore <- 0
k <- 1
#####################
newRSS <- firstRSS
# run while, either if k is equal to 1, or the improvement between k-1th and kth set of beta's is smaller than the parameter e
while (k == 1 | StepScore > e ){
# step to next k
k <- k + 1
# calculate beta's for this k
BetaK <- calcBetaK(prevBeta, Lambda, mX,mY)
# sort the beta's based on absolute value, remove the smallest ones to keep m
absBetaKOrdered <- order(abs(BetaK[,1]), decreasing = T)
BetaK[!BetaK %in% BetaK[absBetaKOrdered,][1:nBeta]] <- 0
# new stepscore, % difference in RSS between new Beta's and previous beta's
StepScore <- calcStepScore(mX,mY,prevBeta,BetaK)
##########
# print(i)
# print(StepScore)
# print(log(StepScore))
# Updating variables for the plot
newRSS <- newRSS - StepScore
i <- i + 1
x_axis <- c(x_axis, i)
y_axis <- c(y_axis, newRSS)
# Add the new bit
# plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(-200, log(firstRSS)))
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS))
###########
# assign current beta's to prevBeta variable for next iteration
prevBeta <- BetaK
}
# calculate several attributes of the linear model, put in dataframes or doubles
BetaFinal <- as.matrix((BetaK))
RSSBetaK <- calcRSS(mX,mY, BetaK)
mYest <- calcYest(mX, BetaFinal)
Rsquared <- calcRsquared(mY, mYest)
adjRsquared <- calcRsquared(mY,mYest, adjusted = T, p = nBeta-2)
Resi <- data.frame(residuals = mY - mYest)
# add these attributes together as a list to make it easily accessible
results <- list(Beta = BetaFinal, RSS = RSSBetaK, Yest = mYest, Rsquared = Rsquared, adjRsquared = adjRsquared, Residuals = Resi)
return(results)
}
##################################
# findMo
modelMM <- calcModelMM(mXairIntercept, mYair, e, nBeta)
calcModelMM <- function(mX,mY,e, nBeta){
# print("Number of variables:")
# print(nBeta)
##################
firstRSS <- 3    # initial RSS
i <- 0          # x axis counter
x_axis <- i     # x axis
y_axis <- firstRSS  # y axis
xlength <- 80  # number of iteration. we actually don't know
y_bottom <- 0.0001
# Initial plot
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 20)
################
if(nBeta > ncol(mX) + 1){
stop("You want to use more variables than there are in the dataset of independent variables")
}
# set the previous beta to initial, random beta's
prevBeta <- getB0(mX)
# calculate X'X
mXtX <- t(mX) %*% mX
# get largest eigenvalue for the square of independent variables
Lambda <- calcLargestEigen(mXtX)
# set initial stepscore to 0, k to 1.
StepScore <- 0
k <- 1
#####################
newRSS <- firstRSS
# run while, either if k is equal to 1, or the improvement between k-1th and kth set of beta's is smaller than the parameter e
while (k == 1 | StepScore > e ){
# step to next k
k <- k + 1
# calculate beta's for this k
BetaK <- calcBetaK(prevBeta, Lambda, mX,mY)
# sort the beta's based on absolute value, remove the smallest ones to keep m
absBetaKOrdered <- order(abs(BetaK[,1]), decreasing = T)
BetaK[!BetaK %in% BetaK[absBetaKOrdered,][1:nBeta]] <- 0
# new stepscore, % difference in RSS between new Beta's and previous beta's
StepScore <- calcStepScore(mX,mY,prevBeta,BetaK)
##########
# print(i)
# print(StepScore)
# print(log(StepScore))
# Updating variables for the plot
newRSS <- newRSS - StepScore
i <- i + 1
x_axis <- c(x_axis, i)
y_axis <- c(y_axis, newRSS)
# Add the new bit
# plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(-200, log(firstRSS)))
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS))
###########
# assign current beta's to prevBeta variable for next iteration
prevBeta <- BetaK
}
# calculate several attributes of the linear model, put in dataframes or doubles
BetaFinal <- as.matrix((BetaK))
RSSBetaK <- calcRSS(mX,mY, BetaK)
mYest <- calcYest(mX, BetaFinal)
Rsquared <- calcRsquared(mY, mYest)
adjRsquared <- calcRsquared(mY,mYest, adjusted = T, p = nBeta-2)
Resi <- data.frame(residuals = mY - mYest)
# add these attributes together as a list to make it easily accessible
results <- list(Beta = BetaFinal, RSS = RSSBetaK, Yest = mYest, Rsquared = Rsquared, adjRsquared = adjRsquared, Residuals = Resi)
return(results)
}
##################################
# f
modelMM <- calcModelMM(mXairIntercept, mYair, e, nBeta)
calcModelMM <- function(mX,mY,e, nBeta){
# print("Number of variables:")
# print(nBeta)
##################
firstRSS <- 3    # initial RSS
i <- 0          # x axis counter
x_axis <- i     # x axis
y_axis <- firstRSS  # y axis
xlength <- 80  # number of iteration. we actually don't know
y_bottom <- 0.0001
# Initial plot
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 20)
################
if(nBeta > ncol(mX) + 1){
stop("You want to use more variables than there are in the dataset of independent variables")
}
# set the previous beta to initial, random beta's
prevBeta <- getB0(mX)
# calculate X'X
mXtX <- t(mX) %*% mX
# get largest eigenvalue for the square of independent variables
Lambda <- calcLargestEigen(mXtX)
# set initial stepscore to 0, k to 1.
StepScore <- 0
k <- 1
#####################
newRSS <- firstRSS
# run while, either if k is equal to 1, or the improvement between k-1th and kth set of beta's is smaller than the parameter e
while (k == 1 | StepScore > e ){
# step to next k
k <- k + 1
# calculate beta's for this k
BetaK <- calcBetaK(prevBeta, Lambda, mX,mY)
# sort the beta's based on absolute value, remove the smallest ones to keep m
absBetaKOrdered <- order(abs(BetaK[,1]), decreasing = T)
BetaK[!BetaK %in% BetaK[absBetaKOrdered,][1:nBeta]] <- 0
# new stepscore, % difference in RSS between new Beta's and previous beta's
StepScore <- calcStepScore(mX,mY,prevBeta,BetaK)
##########
# print(i)
# print(StepScore)
# print(log(StepScore))
# Updating variables for the plot
newRSS <- newRSS - StepScore
i <- i + 1
x_axis <- c(x_axis, i)
y_axis <- c(y_axis, newRSS)
# Add the new bit
# plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(-200, log(firstRSS)))
plot(x_axis, y_axis, xlim = c(0,xlength), ylim = c(y_bottom, firstRSS), pch = 20)
###########
# assign current beta's to prevBeta variable for next iteration
prevBeta <- BetaK
}
# calculate several attributes of the linear model, put in dataframes or doubles
BetaFinal <- as.matrix((BetaK))
RSSBetaK <- calcRSS(mX,mY, BetaK)
mYest <- calcYest(mX, BetaFinal)
Rsquared <- calcRsquared(mY, mYest)
adjRsquared <- calcRsquared(mY,mYest, adjusted = T, p = nBeta-2)
Resi <- data.frame(residuals = mY - mYest)
# add these attributes together as a list to make it easily accessible
results <- list(Beta = BetaFinal, RSS = RSSBetaK, Yest = mYest, Rsquared = Rsquared, adjRsquared = adjRsquared, Residuals = Resi)
return(results)
}
##################################
# fi
modelMM <- calcModelMM(mXairIntercept, mYair, e, nBeta)
knitr::opts_chunk$set(echo = TRUE)
