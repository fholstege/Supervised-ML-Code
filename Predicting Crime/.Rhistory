t$predicted_label == smoke_train$intention_to_smoke
sum(t$predicted_label == smoke_train$intention_to_smoke)/length(smoke_train$intention_to_smoke)
lm(smoke_train$intention_to_smoke ~ x_smoke_train)
lm(smoke_train$intention_to_smoke ~ as.matrix(x_smoke_train))
t_regular = lm(smoke_train$intention_to_smoke ~ as.matrix(x_smoke_train))
t_regular$fitted.values
t$predicted_raw
test_implementation = BoostLogit(x_smoke_train,  smoke_train$intention_to_smoke, 100)
test_implementation$predicted_raw
# train and predict
trained_logitBoost <- LogitBoost(as.matrix(x_smoke_train),smoke_train$intention_to_smoke , nIter=100)
test_regular = predict(trained_logitBoost, x_smoke_test, type ="raw")
test_regular
lm(smoke_train$intention_to_smoke ~ as.matrix(x_smoke_train))
test_lm = lm(smoke_train$intention_to_smoke ~ as.matrix(x_smoke_train))
test_lm$fitted.values
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- glm(vZ ~ as.matrix(mX), weights = vSample_w, family = "Binomial")
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_implementation = BoostLogit(x_smoke_train,  smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- glm(vZ ~ as.matrix(mX), weights = vSample_w, family = "binomial")
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_implementation = BoostLogit(x_smoke_train,  smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
# train and predict
trained_logitBoost <- LogitBoost(as.matrix(x_smoke_train),smoke_train$intention_to_smoke , nIter=100)
BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print(1/vSample_w)
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print(sample_w)
print(1/vSample_w)
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print(vSample_w)
print(1/vSample_w)
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print("Prob")
print(vP[1:5])
print("---")
print("Weights")
print(vSample_w[1:5])
print((1/vSample_w)[1:5])
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print("Prob")
print(vP[1:5])
print("---")
print("Weights")
print(vSample_w[1:5])
print((1/vSample_w)[1:5])
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
print("fited from wls")
print("vWeakClassifierProbabilities$fitted.values")
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print("Prob")
print(vP[1:5])
print("---")
print("Weights")
print(vSample_w[1:5])
print((1/vSample_w)[1:5])
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
print("fited from wls")
print(vWeakClassifierProbabilities$fitted.values)
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print("Prob")
print(vP[1:5])
print("---")
print("Weights")
print(vSample_w[1:5])
print((1/vSample_w)[1:5])
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
print("fited from wls")
print(vWeakClassifierProbabilities$fitted.values{1:5})
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print("Prob")
print(vP[1:5])
print("---")
print("Weights")
print(vSample_w[1:5])
print((1/vSample_w)[1:5])
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
print("fited from wls")
print(vWeakClassifierProbabilities$fitted.values[1:5])
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print("Prob")
print(vP[1:5])
print("---")
print("Weights")
print(vSample_w[1:5])
print((1/vSample_w)[1:5])
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
print("fited from wls")
print(vWeakClassifierProbabilities$fitted.values[1:5])
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
print("Current ensemble prob")
print(vEnsembleProbabilities[1:5])
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print("Prob")
print(vP[1:5])
print("---")
print("Weights")
print(vSample_w[1:5])
print((1/vSample_w)[1:5])
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = vSample_w)
print("fited from wls")
print(vWeakClassifierProbabilities$fitted.values[1:5])
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
print("Current ensemble prob")
print(vEnsembleProbabilities[1:5])
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
BoostLogit <- function(mX, vY, iN_classifiers){
# define the initial weights
iN = nrow(mX)
vW <- rep(1/iN,iN)
# define the initial probabilities
vP <- rep(0.5, iN)
# define the probabilities as chosen by the ensemble
vEnsembleProbabilities = rep(0, iN)
# update integer with each weak classifier added
iClassifier = 0
# Continue updating until as many weak classifiers as defined in iN_classifiers
while(iClassifier < iN_classifiers){
iClassifier = iClassifier+ 1
# Get sample weights based on probabilities - define minimum value to prevent bugs
# Will weigh observations closer to 0.5 (e.g. uncertain ones) more
vSample_w = pmax(vP * (1-vP),1e-24)
# define the response variable
vZ = (vY - vP)/vSample_w
print("Prob")
print(vP[1:5])
print("---")
print("Weights")
print(vSample_w[1:5])
print((1/vSample_w)[1:5])
# get probabilites from a weak classifier
vWeakClassifierProbabilities <- lm(vZ ~ as.matrix(mX), weights = 1/vSample_w)
print("fited from wls")
print(vWeakClassifierProbabilities$fitted.values[1:5])
# update the probabilities of the ensemble with this weak classifier
vEnsembleProbabilities = vEnsembleProbabilities +  (0.5 * vWeakClassifierProbabilities$fitted.values)
print("Current ensemble prob")
print(vEnsembleProbabilities[1:5])
# update current probabilities for the next set of weights
vP <- exp(vEnsembleProbabilities)/(exp(vEnsembleProbabilities) + exp(-vEnsembleProbabilities))
}
resultObj = list(predicted_label = sign(vEnsembleProbabilities),
predicted_raw = vEnsembleProbabilities)
return(resultObj)
}
test_ours <- BoostLogit(x_smoke_train, smoke_train$intention_to_smoke, 100)
